# First Scenario - Desktop

## General Description

This scenario implements a reinforcement learning agent (Q-learning) for dynamic optimisation of system parameters on a Linux desktop.
The agent monitors system metrics in real time (CPU, RAM, swap, temperature, etc.), applies corrective actions (kernel/process tuning), and learns to maximise stability and performance when facing simulated stress situations.

---

## Folder Structure

```
First Scenario - Desktop/
│
├── agent.py              # RL agent: actions, Q-table, system monitoring
├── train_agent.py        # Training script (RL loop, stress tests)
├── gui_interface.py      # Graphical interface to control and visualize the agent
├── monitor_interface.py  # System monitoring GUI (used by the main GUI)
├── q_table.npy           # (Generated) Q-table save file
├── actions_logs/         # Folder containing user action logs (generated by the user)
├── metrics_logs/         # Folder containing script metrics logs (generated by the user)
├── plots/                # Folder containing generated plots (generated by the user)
├── utils/                # Folder containing utilities files for some actions (video, code to compile)
```

---

## Dependencies and Installation

### System Requirements

- Linux (root access required for some actions)
- System tools: `stress-ng`, `vlc`, `iperf3`, `glxgears` (for some stress actions)
- Python 3.8+

### Python Dependencies

From root folder:

```bash
pip install -r requirements.txt
```

### System Tools Installation (example for Ubuntu)

```bash
sudo apt update
sudo apt install stress-ng vlc iperf3 mesa-utils
```

---

## Usage

### 1. **Agent Training (console mode)**

Start RL training with:

```bash
python3 train_agent.py
```

- The agent will simulate stress, apply corrective actions, and learn to optimise the system.
- The Q-table is saved in `q_table.npy`.

### 2. **Graphical Interface**

To control and visualise the agent in real time:

```bash
python3 gui_interface.py
```

- Allows you to launch stress tests, view system metrics, and observe agent reactions.
- Plots, logs and metrics can be exported.

### 3. **Monitoring Only**

To display only the system monitoring interface:

```bash
python3 monitor_interface.py
```

---

## Main Files

- **agent.py**:
  Defines the `EventAgent` class (monitoring, actions, Q-learning, reward, cleanup, etc.).
- **train_agent.py**:
  RL training loop, stress simulation, Q-table management.
- **gui_interface.py**:
  User interface to control the agent, visualise metrics, logs, actions, etc.
- **monitor_interface.py**:
  Graphical display of system metrics (used by the GUI or standalone).
- **q_table.npy**:
  Automatically generated file, contains the saved Q-table.

---

## Expected Results

- **Q-table**: Gradually filled, guides the agent to the best actions for each system state.
- **Logs**: Agent and user actions, system metrics, exportable as CSV.
- **Plots**: Time-series plots showing the evolution of normalised system metrics (CPU, RAM, Disk, Temperature) with markers for user actions and agent reactions in the `plots/` folder.
- **Graphical interface**: Real-time visualization of metrics, actions, and agent reactions.

---

## Tips

- **Run scripts as root** if you want all system actions to work.
- **Adjust bins and episode count** in `agent.py` and `train_agent.py` according to your machine’s power and desired training time.
- **Clean up stress processes** if you abruptly interrupt a script (see the `clean_resources` method).
